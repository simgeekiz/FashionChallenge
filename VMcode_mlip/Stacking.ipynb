{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import cPickle\n",
    "import gzip\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from keras.layers import Dense, concatenate\n",
    "from keras.models import Model, load_model\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "from batch_generator import BatchGenerator, BatchSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_batch_generator(generator_num, **kwargs):\n",
    "    \"\"\"A generator to work with multiple inputs models\n",
    "    \n",
    "    We create a model with a list of multiple input layers when \n",
    "    we use :func:`keras.layers.concatenate`. However,\n",
    "    :class:`batch_generator.BatchGenerator` returns a single tuple \n",
    "    with two arrays, which does not fit to a model with a multiple \n",
    "    input layers. Thus, with this generator, we create the necessary \n",
    "    input for such models.\n",
    "    \n",
    "    Arguments:\n",
    "        generator_num {int} -- number of generators should be created\n",
    "        \\**kwargs -- See :class:`batch_generator.BatchGenerator`\n",
    "        \n",
    "    Yields:\n",
    "        ([ndarray,...,ndarray], ndarray) -- in the tuple; list contains feature arrays from each generator, array out of the list contains the label set\n",
    "    \"\"\"\n",
    "    #generators_list = [BatchGenerator(**kwargs, shuffle=False) for i in range(generator_num)]\n",
    "    gen = BatchGenerator(**kwargs, shuffle=False)\n",
    "    \n",
    "    while True:\n",
    "        nx = gen.next()\n",
    "        Xy_list = [nx, nx, nx, nx]\n",
    "        yield [Xy[0] for Xy in Xy_list], Xy_list[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py:270: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model_vgg16 = load_model('models/VGG16-finetuned-1_epochs.h5')\n",
    "for i, layer in enumerate(model_vgg16.layers):\n",
    "    model_vgg16.layers[i].trainable = False\n",
    "    model_vgg16.layers[i].name = '{}_{}'.format(layer.name, 'vgg16')\n",
    "vgg16_out = model_vgg16.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py:270: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model_vgg19 = load_model('models/VGG19-finetuned-4000_steps.h5')\n",
    "for i, layer in enumerate(model_vgg19.layers):\n",
    "    model_vgg19.layers[i].trainable = False\n",
    "    model_vgg19.layers[i].name = '{}_{}'.format(layer.name, 'vgg19')\n",
    "vgg19_out = model_vgg19.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py:270: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model_xception = load_model('models/Xception-finetuned-4000_steps.h5')\n",
    "for i, layer in enumerate(model_xception.layers):\n",
    "    model_xception.layers[i].trainable = False\n",
    "    model_xception.layers[i].name = '{}_{}'.format(layer.name, 'xception')\n",
    "xception_out = model_xception.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py:270: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model_resnet50 = load_model('models/ResNet50-finetuned-1_epochs.h5')\n",
    "for i, layer in enumerate(model_resnet50.layers):\n",
    "    model_resnet50.layers[i].trainable = False\n",
    "    model_resnet50.layers[i].name = '{}_{}'.format(layer.name, 'resnet50')\n",
    "resnet50_out = model_resnet50.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_0 = concatenate([vgg16_out, vgg19_out, xception_out, resnet50_out])\n",
    "output = Dense(228, activation='sigmoid', name='main_output')(merge_0)\n",
    "model = Model(inputs=[model_vgg16.input, model_vgg19.input, model_xception.input, model_resnet50.input], outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('models/stacked-300_steps.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = os.path.abspath('data/')\n",
    "\n",
    "images_path_train = os.path.join(input_path, 'train/')\n",
    "images_path_validation = os.path.join(input_path, 'validation/')\n",
    "images_path_test = os.path.join(input_path, 'test/')\n",
    "\n",
    "# Labels\n",
    "with gzip.open('data/y_train.pickle','rb') as fp:\n",
    "    y_train = pickle.load(fp)\n",
    "with gzip.open('data/y_validation.pickle','rb') as fp:\n",
    "    y_validation = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "150/150 [==============================] - 650s 4s/step - loss: 0.0743\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 628s 4s/step - loss: 0.0636\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 628s 4s/step - loss: 0.0605\n",
      "Epoch 1/1\n",
      "144/150 [===========================>..] - ETA: 25s - loss: 0.0591"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "steps = int(len(y_train)/batch_size)\n",
    "steps = 150\n",
    "epochs = 1\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "input_num = 4#len(model.input_layers)\n",
    "\n",
    "train_gen_multi = multiple_batch_generator(4, \n",
    "                                      input_dir=images_path_train,\n",
    "                                      y=y_train,\n",
    "                                      batch_size=batch_size)\n",
    "\n",
    "for i in range(5):\n",
    "    model.fit_generator(train_gen_multi, steps_per_epoch=steps, epochs=epochs)\n",
    "    model.save( \"models/stacked-{}_steps.h5\".format((i+1)*steps+300) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1,0,0,1,1],\n",
    "        [0,0,1,0,1],\n",
    "        [0,1,1,0,0],\n",
    "        [1,1,1,1,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(labelmatrix):\n",
    "    newlabels = []\n",
    "    for labelrow in labelmatrix:\n",
    "        labels = []\n",
    "        for i,label in enumerate(labelrow):\n",
    "            if label == 1:\n",
    "                labels.append(i)\n",
    "        newlabels.append(labels)\n",
    "    return newlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_categorical(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
