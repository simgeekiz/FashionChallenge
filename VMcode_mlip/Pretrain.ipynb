{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from os.path import join\n",
    "\n",
    "from keras.applications import VGG16, VGG19, InceptionV3, Xception, ResNet50\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from batch_generator import BatchGenerator, BatchSequence\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "\n",
    "import gzip, pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images\n",
    "images_path_train = os.path.abspath('data/train/')\n",
    "images_path_validation = os.path.abspath('data/validation/')\n",
    "images_path_test = os.path.abspath('data/test/')\n",
    "\n",
    "# Labels\n",
    "with gzip.open('data/y_train.pickle','rb') as fp:\n",
    "    y_train = pickle.load(fp)\n",
    "with gzip.open('data/y_validation.pickle','rb') as fp:\n",
    "    y_validation = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics / callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics(Callback):\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.mean_f1s = []\n",
    "        self.recalls = []\n",
    "        self.precisions = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n",
    "        y_true = self.validation_data[1]\n",
    "\n",
    "        mean_f1 = f1_score(y_true, y_pred, average='micro')\n",
    "        recall = recall_score(y_true, y_pred, average='micro')\n",
    "        precision = precision_score(y_true, y_pred, average='micro')\n",
    "        self.mean_f1s.append(mean_f1)\n",
    "        self.recalls.append(recall)\n",
    "        self.precisions.append(precision)\n",
    "\n",
    "        print('mean_F1: {} — precision: {} — recall: {}'.format(mean_f1, precision, recall))\n",
    "\n",
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "filepath=\"models/inceptionV3-fc-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128*2 # 128 per GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the generators\n",
    "training_gen = BatchGenerator(input_dir=images_path_train, y=y_train, batch_size=batch_size)\n",
    "val_gen = BatchSequence(input_dir=images_path_validation, y=y_validation, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 20s 0us/step\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=(290,290,3))\n",
    "\n",
    "    # Adding the last two fully-connected layers\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x) # global average pooling (flatten)\n",
    "    x = Dense(1024, activation='relu')(x) # should be rather large with 228 output labels\n",
    "    x = Dropout(0.5)(x)\n",
    "    y = Dense(228, activation='sigmoid')(x) # sigmoid instead of softmax to have independent probabilities\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train only the top layer\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-GPU data parallelism\n",
    "multi_model = multi_gpu_model(model, gpus=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use binary loss instead of categorical loss to penalize each output independently\n",
    "multi_model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3964/3964 [==============================] - 20349s 5s/step - loss: 0.0703\n"
     ]
    }
   ],
   "source": [
    "# Train the network\n",
    "epochs = 1\n",
    "steps = int(y_train.shape[0]/batch_size) + 1\n",
    "\n",
    "#history = model.fit_generator(training_gen, steps_per_epoch=steps, epochs=1, callbacks=[checkpoint, metrics], validation_data=val_gen)\n",
    "history = multi_model.fit_generator(training_gen, steps_per_epoch=steps, epochs=epochs)\n",
    "\n",
    "model.save(\"models/VGG19-fc-{}_epochs.h5\".format(epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py:270: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 255s 3s/step\n",
      "[models/VGG19-fc-1_epochs.h5] Precision: 0.8470145509282488 Recall: 0.21260169769023451 F1: 0.33989046832843395\n"
     ]
    }
   ],
   "source": [
    "predict_gen = BatchSequence(input_dir=images_path_validation, y=y_validation, batch_size=128)\n",
    "\n",
    "for path in ['models/VGG19-fc-1_epochs.h5', 'models/Xception-fc-1_epochs.h5', 'models/VGG16-fc-1_epochs.h5', 'models/ResNet50-fc-1_epochs.h5']:\n",
    "    model = load_model(path)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy') # training configuration\n",
    "    \n",
    "    predictions = model.predict_generator(predict_gen, verbose=1)\n",
    "\n",
    "    y_true = y_validation\n",
    "    y_pred = (predictions > 0.5).astype(int)\n",
    "\n",
    "    pr = precision_score(y_true, y_pred, average='micro')\n",
    "    rc = recall_score(y_true, y_pred, average='micro')\n",
    "    f1 = f1_score(y_true, y_pred, average='micro')\n",
    "\n",
    "    print(\"[{}] Precision: {} Recall: {} F1: {}\".format(path, pr, rc, f1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
