{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from os.path import join\n",
    "\n",
    "from keras.applications import VGG16, InceptionV3\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "#sys.path.append(\"../data_preparation/\")\n",
    "\n",
    "from batch_generator import BatchGenerator, BatchSequence\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datadir = os.getcwd()\n",
    "input_path = os.path.abspath('data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train={}\n",
    "test={}\n",
    "validation={}\n",
    "with open(os.path.join(input_path, 'train.json')) as json_data:\n",
    "    train= json.load(json_data)\n",
    "with open(os.path.join(input_path, 'test.json')) as json_data:\n",
    "    test= json.load(json_data)\n",
    "with open(os.path.join(input_path, 'validation.json')) as json_data:\n",
    "    validation = json.load(json_data)\n",
    "\n",
    "print('Train No. of images: %d'%(len(train['images'])))\n",
    "print('Test No. of images: %d'%(len(test['images'])))\n",
    "print('Validation No. of images: %d'%(len(validation['images'])))\n",
    "\n",
    "# JSON TO PANDAS DATAFRAME\n",
    "# train data\n",
    "train_img_url=train['images']\n",
    "train_img_url=pd.DataFrame(train_img_url)\n",
    "train_ann=train['annotations']\n",
    "train_ann=pd.DataFrame(train_ann)\n",
    "train=pd.merge(train_img_url, train_ann, on='imageId', how='inner')\n",
    "\n",
    "# test data\n",
    "test=pd.DataFrame(test['images'])\n",
    "\n",
    "# Validation Data\n",
    "val_img_url=validation['images']\n",
    "val_img_url=pd.DataFrame(val_img_url)\n",
    "val_ann=validation['annotations']\n",
    "val_ann=pd.DataFrame(val_ann)\n",
    "validation=pd.merge(val_img_url, val_ann, on='imageId', how='inner')\n",
    "\n",
    "datas = {'Train': train, 'Test': test, 'Validation': validation}\n",
    "for data in datas.values():\n",
    "    data['imageId'] = data['imageId'].astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(train.labelId)\n",
    "#images_path_train = os.path.abspath('data/train/')\n",
    "images_path_validation = os.path.abspath('data/validation/')\n",
    "images_path_test = os.path.abspath('data/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_batch_generator(generator_num, **kwargs):\n",
    "    \"\"\"A generator to work with multiple inputs models\n",
    "    \n",
    "    We create a model with a list of multiple input layers when \n",
    "    we use :func:`keras.layers.concatenate`. However,\n",
    "    :class:`batch_generator.BatchGenerator` returns a single tuple \n",
    "    with two arrays, which does not fit to a model with a multiple \n",
    "    input layers. Thus, with this generator, we create the necessary \n",
    "    input for such models.\n",
    "    \n",
    "    Arguments:\n",
    "        generator_num {int} -- number of generators should be created\n",
    "        \\**kwargs -- See :class:`batch_generator.BatchGenerator`\n",
    "        \n",
    "    Yields:\n",
    "        ([ndarray,...,ndarray], ndarray) -- in the tuple; list contains feature arrays from each generator, array out of the list contains the label set\n",
    "    \"\"\"\n",
    "    generators_list = [BatchGenerator(**kwargs) for i in range(generator_num)]\n",
    "    \n",
    "    while True:\n",
    "        Xy_list = [gen.next() for gen in generators_list]\n",
    "        yield [Xy[0] for Xy in Xy_list], Xy_list[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this on the predictions to fix the label order\n",
    "def remap(predictions):\n",
    "    ordering = [1, 10, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 11, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 12, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 13, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 14, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 15, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 16, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 17, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 18, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 19, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 2, 20, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 21, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 22, 220, 221, 222, 223, 224, 225, 226, 227, 228, 23, 24, 25, 26, 27, 28, 29, 3, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 4, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 5, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 6, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 7, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 8, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 9, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
    "    fixed = np.zeros(predictions.shape)\n",
    "\n",
    "    for j in range(predictions.shape[0]):\n",
    "        for i in range(predictions.shape[1]):\n",
    "            fixed[j][ordering[i]-1] = predictions[j][i]\n",
    "            \n",
    "    return fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/311 [==========>...................] - ETA: 1:18:23"
     ]
    }
   ],
   "source": [
    "y_test = np.zeros((39706,1))\n",
    "predict_gen = BatchSequence(input_dir=images_path_test, y=y_test, batch_size=128)\n",
    "modelvgg16 = load_model('../models/VGG16-finetuned-1_epochs.h5')\n",
    "predictions = modelvgg16.predict_generator(predict_gen, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0\n",
    "y_pred = (predictions > threshold)\n",
    "\n",
    "results =[ \" \".join([str(i-1) for i in j if i !=0]) for j in y_pred*range(1,229)]\n",
    "results = pd.Series(results, name='label_id')\n",
    "submission = pd.concat([pd.Series(range(1,y_pred.shape[0]+1), name='image_id', dtype=object), results], axis=1)\n",
    "submission.to_csv(\"vgg16.csv\", index=False, quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py:270: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311/311 [==============================] - 951s 3s/step\n"
     ]
    }
   ],
   "source": [
    "y_test = np.zeros((39706,1))\n",
    "predict_gen = BatchSequence(input_dir=images_path_test, y=y_test, batch_size=128)\n",
    "modelvgg19 = load_model('models/VGG19-finetuned-4000_steps.h5')\n",
    "modelvgg19.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "predictions = modelvgg19.predict_generator(predict_gen, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.load('stacked_predictions_15000_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('vgg19_compiled_predictions_test', predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = remap(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39706, 228)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_thresholds(predictions, thresholds):\n",
    "    opt = np.empty(predictions.shape, dtype='int')\n",
    "    for i,t in enumerate(thresholds):\n",
    "        opt[:,i] = (predictions[:,i] > t).astype(int)\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = remap(predictions)\n",
    "\n",
    "threshold = 0.15\n",
    "t = np.load('optimize_thresholds.npy')\n",
    "\n",
    "y_pred = (predictions > threshold)\n",
    "y_pred2 = apply_thresholds(predictions, t)\n",
    "\n",
    "results_glb =[ \" \".join([str(i) for i in j if i !=0]) for j in y_pred*range(1,229)]\n",
    "results_glb = pd.Series(results_glb, name='label_id')\n",
    "submission_glb = pd.concat([pd.Series(range(1,y_pred.shape[0]+1), name='image_id', dtype=object), results_glb], axis=1)\n",
    "\n",
    "results_opt =[ \" \".join([str(i) for i in j if i !=0]) for j in y_pred2*range(1,229)]\n",
    "results_opt = pd.Series(results_opt, name='label_id')\n",
    "submission_opt = pd.concat([pd.Series(range(1,y_pred.shape[0]+1), name='image_id', dtype=object), results_opt], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17 20 62 66 105 214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>17 62 66 105 153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2 20 44 66 154 171 180 186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>53 66 138 153 164 190 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>44 62 66 70 133 153 171 184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>17 20 62 66 98 105 153 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>66 95 171 175 184 189 214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>20 62 66 105 116 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>66 74 138 144 171 176 193 217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>19 49 61 105 106 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>15 66 115 176 189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>17 18 66 148 153 164 171 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>17 20 62 66 105 116 171 184 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>66 74 137 138 144 171 176 193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>17 66 87 114 171 214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>17 19 44 62 66 116 171 184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>49 53 106 138 153 164 190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>17 20 47 62 66 98 105 148 153 171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>17 19 66 171 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>17 18 44 66 98 105 128 153 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>106 113 138 153 164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>17 20 47 62 66 99 171 180 186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>2 17 66 105 148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>17 20 62 66 171 214 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>19 49 105 106 183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>66 118 133 171 180 186 203 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>17 19 106 115 181 187 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>17 65 66 73 91 105 143 224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>15 66 115 137 176 189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>66 73 105 153 205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39676</th>\n",
       "      <td>39677</td>\n",
       "      <td>17 19 49 66 78 105 142 148 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39677</th>\n",
       "      <td>39678</td>\n",
       "      <td>62 66 105 153 204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39678</th>\n",
       "      <td>39679</td>\n",
       "      <td>17 49 105 106 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39679</th>\n",
       "      <td>39680</td>\n",
       "      <td>17 19 66 78 88 105 148 153 205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39680</th>\n",
       "      <td>39681</td>\n",
       "      <td>17 19 66 78 79 105 148 153 205 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39681</th>\n",
       "      <td>39682</td>\n",
       "      <td>28 49 88 91 105 106 205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39682</th>\n",
       "      <td>39683</td>\n",
       "      <td>66 88 105 113 138 153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39683</th>\n",
       "      <td>39684</td>\n",
       "      <td>17 19 66 105 148 153 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39684</th>\n",
       "      <td>39685</td>\n",
       "      <td>17 66 105 138 153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39685</th>\n",
       "      <td>39686</td>\n",
       "      <td>66 105 153 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39686</th>\n",
       "      <td>39687</td>\n",
       "      <td>17 49 66 105 138 153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39687</th>\n",
       "      <td>39688</td>\n",
       "      <td>17 66 148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39688</th>\n",
       "      <td>39689</td>\n",
       "      <td>17 88 105 113 138 153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39689</th>\n",
       "      <td>39690</td>\n",
       "      <td>66 105 138 153 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39690</th>\n",
       "      <td>39691</td>\n",
       "      <td>66 74 105 113 138 153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39691</th>\n",
       "      <td>39692</td>\n",
       "      <td>66 88 105 138 153 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39692</th>\n",
       "      <td>39693</td>\n",
       "      <td>17 66 148 171 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39693</th>\n",
       "      <td>39694</td>\n",
       "      <td>17 66 105 153 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39694</th>\n",
       "      <td>39695</td>\n",
       "      <td>66 105 138 153 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39695</th>\n",
       "      <td>39696</td>\n",
       "      <td>105 106 138 153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39696</th>\n",
       "      <td>39697</td>\n",
       "      <td>66 97 105 138 153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39697</th>\n",
       "      <td>39698</td>\n",
       "      <td>17 19 49 88 91 105 106 205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39698</th>\n",
       "      <td>39699</td>\n",
       "      <td>66 74 105 138 153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39699</th>\n",
       "      <td>39700</td>\n",
       "      <td>74 88 105 113 138 153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39700</th>\n",
       "      <td>39701</td>\n",
       "      <td>17 19 66 78 105 148 153 205 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39701</th>\n",
       "      <td>39702</td>\n",
       "      <td>66 133 170 171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39702</th>\n",
       "      <td>39703</td>\n",
       "      <td>17 66 88 105 113 138 153 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39703</th>\n",
       "      <td>39704</td>\n",
       "      <td>66 74 105 113 138 153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39704</th>\n",
       "      <td>39705</td>\n",
       "      <td>17 19 49 78 105 106 153 222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39705</th>\n",
       "      <td>39706</td>\n",
       "      <td>66 73 78 97 105 153 205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39706 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id                            label_id\n",
       "0            1                 17 20 62 66 105 214\n",
       "1            2                    17 62 66 105 153\n",
       "2            3          2 20 44 66 154 171 180 186\n",
       "3            4           53 66 138 153 164 190 222\n",
       "4            5         44 62 66 70 133 153 171 184\n",
       "5            6          17 20 62 66 98 105 153 222\n",
       "6            7           66 95 171 175 184 189 214\n",
       "7            8                20 62 66 105 116 222\n",
       "8            9       66 74 138 144 171 176 193 217\n",
       "9           10                19 49 61 105 106 222\n",
       "10          11                   15 66 115 176 189\n",
       "11          12        17 18 66 148 153 164 171 222\n",
       "12          13     17 20 62 66 105 116 171 184 222\n",
       "13          14       66 74 137 138 144 171 176 193\n",
       "14          15                17 66 87 114 171 214\n",
       "15          16          17 19 44 62 66 116 171 184\n",
       "16          17           49 53 106 138 153 164 190\n",
       "17          18   17 20 47 62 66 98 105 148 153 171\n",
       "18          19                    17 19 66 171 222\n",
       "19          20      17 18 44 66 98 105 128 153 222\n",
       "20          21                 106 113 138 153 164\n",
       "21          22       17 20 47 62 66 99 171 180 186\n",
       "22          23                     2 17 66 105 148\n",
       "23          24             17 20 62 66 171 214 222\n",
       "24          25                   19 49 105 106 183\n",
       "25          26      66 118 133 171 180 186 203 222\n",
       "26          27           17 19 106 115 181 187 222\n",
       "27          28          17 65 66 73 91 105 143 224\n",
       "28          29               15 66 115 137 176 189\n",
       "29          30                   66 73 105 153 205\n",
       "...        ...                                 ...\n",
       "39676    39677      17 19 49 66 78 105 142 148 222\n",
       "39677    39678                   62 66 105 153 204\n",
       "39678    39679                   17 49 105 106 222\n",
       "39679    39680      17 19 66 78 88 105 148 153 205\n",
       "39680    39681  17 19 66 78 79 105 148 153 205 222\n",
       "39681    39682             28 49 88 91 105 106 205\n",
       "39682    39683               66 88 105 113 138 153\n",
       "39683    39684            17 19 66 105 148 153 222\n",
       "39684    39685                   17 66 105 138 153\n",
       "39685    39686                      66 105 153 222\n",
       "39686    39687                17 49 66 105 138 153\n",
       "39687    39688                           17 66 148\n",
       "39688    39689               17 88 105 113 138 153\n",
       "39689    39690                  66 105 138 153 222\n",
       "39690    39691               66 74 105 113 138 153\n",
       "39691    39692               66 88 105 138 153 222\n",
       "39692    39693                   17 66 148 171 222\n",
       "39693    39694                   17 66 105 153 222\n",
       "39694    39695                  66 105 138 153 222\n",
       "39695    39696                     105 106 138 153\n",
       "39696    39697                   66 97 105 138 153\n",
       "39697    39698          17 19 49 88 91 105 106 205\n",
       "39698    39699                   66 74 105 138 153\n",
       "39699    39700               74 88 105 113 138 153\n",
       "39700    39701     17 19 66 78 105 148 153 205 222\n",
       "39701    39702                      66 133 170 171\n",
       "39702    39703        17 66 88 105 113 138 153 222\n",
       "39703    39704               66 74 105 113 138 153\n",
       "39704    39705         17 19 49 78 105 106 153 222\n",
       "39705    39706             66 73 78 97 105 153 205\n",
       "\n",
       "[39706 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_glb.to_csv(\"stacked_final_glb_15.csv\", index=False, quoting=csv.QUOTE_NONE)\n",
    "#submission_opt.to_csv(\"stacked_final_opt_1530.csv\", index=False, quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([j[1:] for j in y_train])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define multisequencegenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_sequence_generator(generator_num, **kwargs):\n",
    "    \"\"\"A generator to work with multiple inputs models\n",
    "    \n",
    "    We create a model with a list of multiple input layers when \n",
    "    we use :func:`keras.layers.concatenate`. However,\n",
    "    :class:`batch_generator.BatchGenerator` returns a single tuple \n",
    "    with two arrays, which does not fit to a model with a multiple \n",
    "    input layers. Thus, with this generator, we create the necessary \n",
    "    input for such models.\n",
    "    \n",
    "    Arguments:\n",
    "        generator_num {int} -- number of generators should be created\n",
    "        \\**kwargs -- See :class:`batch_generator.BatchGenerator`\n",
    "        \n",
    "    Yields:\n",
    "        ([ndarray,...,ndarray], ndarray) -- in the tuple; list contains feature arrays from each generator, array out of the list contains the label set\n",
    "    \"\"\"\n",
    "    generators_list = [SequenceGenerator(**kwargs) for i in range(generator_num)]\n",
    "    \n",
    "    while True:\n",
    "        Xy_list = [gen.next() for gen in generators_list]\n",
    "        yield [Xy[0] for Xy in Xy_list], Xy_list[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create testing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('models/stacked-700_steps.h5')\n",
    "y_test = np.zeros((39706,1))\n",
    "batch_size = 64\n",
    "test_steps = int(len(y_test)/batch_size)\n",
    "input_num = 4#len(model.input_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator_multi = multiple_batch_generator(generator_num=input_num,\n",
    "                                               input_dir=images_path_test,\n",
    "                                               y=y_test,\n",
    "                                               batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620/620 [==============================] - 2795s 5s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(test_generator_multi, steps=test_steps, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('stacked_predictions_test', test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create validation predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip, pickle\n",
    "with gzip.open('data/y_validation.pickle','rb') as fp:\n",
    "    y_validation = pickle.load(fp)\n",
    "\n",
    "y_valid = np.zeros((9897,1))\n",
    "\n",
    "#valid_steps = int(len(y_valid)/batch_size)+1\n",
    "predict_gen = BatchSequence(input_dir=images_path_validation, y=y_valid, batch_size=128)\n",
    "modelvgg19 = load_model('models/VGG19-finetuned-4000_steps.h5')\n",
    "\n",
    "vgg19_valid_predictions = modelvgg19.predict_generator(predict_gen, verbose=1)\n",
    "\n",
    "np.save('vgg19_validation_predictions', vgg19_valid_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9897, 228)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg19_valid_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('stacked_predictions_validation', valid_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict_generator with multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "val_steps = int(len(y_validation[:500])/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_num = len(model.input_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator_multi = multiple_batch_generator(generator_num=input_num,\n",
    "                                               input_dir=images_path_validation,\n",
    "                                               y=y_validation\n",
    "                                               [:500],\n",
    "                                               batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackedmodel = load_model('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths\n",
    "input_path = os.path.abspath('../../mlipdata/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('pickles/binarizer.pickle', 'rb') as pickle_file:\n",
    "    binarizer = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path_validation = os.path.join(input_path, 'files/validation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with file_io.FileIO('../../mlipdata/server_validation.pickle', mode='rb') as fp:\n",
    "        data = gzip.GzipFile(fileobj=fp)\n",
    "        y_validation = cPickle.load(data)\n",
    "y_validation = np.array([j[1:] for j in y_validation])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation={}\n",
    "with open(os.path.join(input_path, 'validation.json')) as json_data:\n",
    "    validation = json.load(json_data)\n",
    "\n",
    "validation_img_url = validation['images']\n",
    "validation_img_url = pd.DataFrame(validation_img_url)\n",
    "validation_ann = validation['annotations']\n",
    "validation_ann = pd.DataFrame(validation_ann)\n",
    "validation = pd.merge(validation_img_url, validation_ann, on='imageId', how='inner')\n",
    "validation['imageId'] = validation['imageId'].astype(np.uint32)\n",
    "\n",
    "#y_validation = np.array(validation.labelId)\n",
    "#y_validation_bin = binarizer.transform(y_validation)\n",
    "\n",
    "del validation_img_url\n",
    "del validation_ann\n",
    "del validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict_generator with multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "val_steps = int(len(y_validation[:500])/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_num = len(model.input_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator_multi = multiple_batch_generator(generator_num=input_num,\n",
    "                                               input_dir=images_path_validation,\n",
    "                                               y=y_validation\n",
    "                                               [:500],\n",
    "                                               batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 242s 24s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(val_generator_multi, steps=val_steps, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_validation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-71846f6c32c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_validation' is not defined"
     ]
    }
   ],
   "source": [
    "y_true = y_validation[:500]\n",
    "y_pred = (predictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0715523392111 Recall: 0.181536074476 F1: 0.102646585758\n"
     ]
    }
   ],
   "source": [
    "pr = precision_score(y_true, y_pred, average='micro')\n",
    "rc = recall_score(y_true, y_pred, average='micro')\n",
    "f1 = f1_score(y_true, y_pred, average='micro')\n",
    "\n",
    "print(\"Precision: {} Recall: {} F1: {}\".format(pr, rc, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 242s 24s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(val_generator_multi, steps=val_steps, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_validation[:500]\n",
    "y_pred = (predictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0715523392111 Recall: 0.181536074476 F1: 0.102646585758\n"
     ]
    }
   ],
   "source": [
    "pr = precision_score(y_true, y_pred, average='micro')\n",
    "rc = recall_score(y_true, y_pred, average='micro')\n",
    "f1 = f1_score(y_true, y_pred, average='micro')\n",
    "\n",
    "print(\"Precision: {} Recall: {} F1: {}\".format(pr, rc, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model : the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 4 array(s), but instead got the following list of 1 arrays: [array([[[[146, 143, 138],\n         [202, 173, 159],\n         [185, 147, 124],\n         ...,\n         [197, 182, 149],\n         [198, 187, 151],\n         [192, 185, 148]],\n\n        [[147, 144, 137],\n ...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b77a02e581ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredict_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages_path_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstackedmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../models/stacked-400_steps.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstackedmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/sekiz/FashionChallenge/.env/local/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/FashionChallenge/.env/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   2538\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2540\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2541\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2542\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/FashionChallenge/.env/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1937\u001b[0m         \"\"\"\n\u001b[1;32m   1938\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[0;32m-> 1939\u001b[0;31m                                     self._feed_input_shapes)\n\u001b[0m\u001b[1;32m   1940\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1941\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sekiz/FashionChallenge/.env/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model : the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 4 array(s), but instead got the following list of 1 arrays: [array([[[[146, 143, 138],\n         [202, 173, 159],\n         [185, 147, 124],\n         ...,\n         [197, 182, 149],\n         [198, 187, 151],\n         [192, 185, 148]],\n\n        [[147, 144, 137],\n ..."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
