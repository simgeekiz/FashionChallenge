{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "from keras.applications import VGG16, VGG19, InceptionV3, Xception, ResNet50\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from batch_generator import BatchGenerator, BatchSequence\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "\n",
    "import gzip, pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images\n",
    "images_path_train = os.path.abspath('data/train/')\n",
    "images_path_validation = os.path.abspath('data/validation/')\n",
    "images_path_test = os.path.abspath('data/test/')\n",
    "\n",
    "# Labels\n",
    "with gzip.open('data/y_train.pickle','rb') as fp:\n",
    "    y_train = pickle.load(fp)\n",
    "with gzip.open('data/y_validation.pickle','rb') as fp:\n",
    "    y_validation = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics / callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics(Callback):\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.mean_f1s = []\n",
    "        self.recalls = []\n",
    "        self.precisions = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n",
    "        y_true = self.validation_data[1]\n",
    "\n",
    "        mean_f1 = f1_score(y_true, y_pred, average='micro')\n",
    "        recall = recall_score(y_true, y_pred, average='micro')\n",
    "        precision = precision_score(y_true, y_pred, average='micro')\n",
    "        self.mean_f1s.append(mean_f1)\n",
    "        self.recalls.append(recall)\n",
    "        self.precisions.append(precision)\n",
    "\n",
    "        print('mean_F1: {} — precision: {} — recall: {}'.format(mean_f1, precision, recall))\n",
    "\n",
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "filepath=\"models/inceptionV3-fc-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128*2 # 128 per GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the generators\n",
    "training_gen = BatchGenerator(input_dir=images_path_train, y=y_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen = BatchSequence(input_dir=images_path_validation, y=y_validation, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model       trainable layers\n",
    "vgg16       4\n",
    "vgg19       5\n",
    "exception   6\n",
    "inception   17\n",
    "resnet50    7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that takes modelpath and number of epochs and trains the model at the specified path for the number of epochs. After each epoch the model is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(modelname, epochs):    \n",
    "    with tf.device('/cpu:0'):\n",
    "        model = load_model('models/{}-finetuned-3500_steps.h5'.format(modelname)) \n",
    "        #models/{}-fc-1_epochs.h5\n",
    "        trainable_layers = layer_dict[modelname[:5]]\n",
    "        for layer in model.layers[:trainable_layers]:\n",
    "            layer.trainable = False\n",
    "        for layer in model.layers[trainable_layers:]:\n",
    "            layer.trainable = True\n",
    "\n",
    "    # Multi-GPU data parallelism\n",
    "    multi_model = multi_gpu_model(model, gpus=4)\n",
    "\n",
    "    # Use binary loss instead of categorical loss to penalize each output independently, also use lower learning rate\n",
    "    optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    multi_model.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "\n",
    "    steps = int(y_train.shape[0]/batch_size) + 1\n",
    "    steps = 250\n",
    "\n",
    "    for i in range(14, epochs):\n",
    "        history = multi_model.fit_generator(training_gen, steps_per_epoch=steps, epochs=1)\n",
    "        model.save( \"models/{}-finetuned-{}_steps.h5\".format(modelname, (i+1)*steps) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train all models, if you want to train only 1 model then remove the loop :P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py:270: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "250/250 [==============================] - 1084s 4s/step - loss: 0.0556\n",
      "Epoch 1/1\n",
      "250/250 [==============================] - 1073s 4s/step - loss: 0.0553\n"
     ]
    }
   ],
   "source": [
    "models = ['Xception', 'VGG16', 'VGG19', 'ResNet50']\n",
    "layer_dict = {'VGG16':-8, 'VGG19':-9, 'Xcept':-10, 'ResNe':-11, 'Incep':-21}\n",
    "epochs = 16\n",
    "\n",
    "train_network('VGG19', epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images_path_validation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-73b1893605e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages_path_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m for path in ['models/Xception-finetuned-4000_steps.h5','models/ResNet50-finetuned-1_epochs.h5', 'models/VGG19-finetuned-1_epochs.h5', \n\u001b[1;32m      4\u001b[0m              'models/Xception-finetuned-1_epochs.h5', 'models/VGG16-finetuned-1_epochs.h5']:\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images_path_validation' is not defined"
     ]
    }
   ],
   "source": [
    "predict_gen = BatchSequence(input_dir=images_path_validation, y=y_validation, batch_size=128)\n",
    "\n",
    "for path in ['models/Xception-finetuned-4000_steps.h5','models/ResNet50-finetuned-1_epochs.h5', 'models/VGG19-finetuned-1_epochs.h5', \n",
    "             'models/Xception-finetuned-1_epochs.h5', 'models/VGG16-finetuned-1_epochs.h5']:\n",
    "    model = load_model(path)\n",
    "    # Train only the top few layers\n",
    "        \n",
    "    optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy') # training configuration\n",
    "    \n",
    "    predictions = model.predict_generator(predict_gen, verbose=1)\n",
    "\n",
    "    y_true = y_validation\n",
    "    y_pred = (predictions > 0.5).astype(int)\n",
    "\n",
    "    pr = precision_score(y_true, y_pred, average='micro')\n",
    "    rc = recall_score(y_true, y_pred, average='micro')\n",
    "    f1 = f1_score(y_true, y_pred, average='micro')\n",
    "\n",
    "    print(\"[{}] Precision: {} Recall: {} F1: {}\".format(path, pr, rc, f1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[models/VGG19-finetuned-4000_steps.h5] Precision: 0.8499547951874261 Recall: 0.30783859348631015 F1: 0.45197855029585804\n",
    "[models/Xception-finetuned-4000_steps.h5] Precision: 0.4570333880678708 Recall: 0.14722551069242587 F1: 0.22270908744522763"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
