{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required adaptation to jupyter!\n",
    "pred = np.load('stacked_predictions_15000_validation.npy')\n",
    "with gzip.open('data/y_validation.pickle','rb') as fp:\n",
    "    labels = pickle.load(fp)\n",
    "\n",
    "#labels = labels[::,1::]\n",
    "\n",
    "y_true = np.transpose(labels)\n",
    "predictions = np.transpose(pred)\n",
    "\n",
    "# Baseline threshold and F1\n",
    "y_pred = (predictions > 0.20).astype(int)\n",
    "f1 = f1_score(y_true, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using this adjusted threshold function actually improves the f1 on the validation set by ~0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresholds(y_true, predictions, num_labels=228):\n",
    "    thresholds = []\n",
    "    for i in range(num_labels):\n",
    "        labels_i = y_true[i]\n",
    "        activations_i = predictions[i]\n",
    "        threshold = equidistant_threshold(labels_i, activations_i)\n",
    "        thresholds.append(threshold)\n",
    "    np.array(thresholds)\n",
    "    return(thresholds)\n",
    "\n",
    "# Input function for individual thresholds\n",
    "def equidistant_threshold(labels_i,activations_i, distance=0.1, rng=(15,30)):\n",
    "    best_threshold = 0.5\n",
    "    best_f1 = 0.0\n",
    "    for i in range(rng[0], rng[1], 1): \n",
    "        threshold = i/100.\n",
    "        pred_i = (activations_i > threshold).astype(int)\n",
    "        f1 = f1_score(labels_i, pred_i)\n",
    "        #print('f1: {}'.format(f1))\n",
    "        if(f1>best_f1):\n",
    "            #print('!!newbest!!')\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "    return(best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "t = thresholds(y_true, predictions)\n",
    "pred_equi = np.empty((228,9897))\n",
    "for i, threshold in enumerate(t):\n",
    "    pred_equi[i,:] = (predictions[i,:] > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5917886355984234"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true, pred_equi, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5732677871520627"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true, (predictions > 0.2).astype(int), average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this to save optimized thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('optimize_thresholds', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All functions used in cells bellow\n",
    "\n",
    "# Make individual thresholds for all the labels output in one array. Uses \n",
    "# either the equidistant spacing or successive splitting method for searching\n",
    "def thresholds(y_true, predictions, method='equidistant', num_labels=228):\n",
    "    thresholds = []\n",
    "    for i in range(num_labels):\n",
    "        labels_i = y_true[i]\n",
    "        activations_i = predictions[i]\n",
    "        if(method=='equidistant'):\n",
    "            threshold = equidistant_threshold(labels_i, activations_i)\n",
    "            thresholds.append(threshold)\n",
    "        if(method=='successive'):\n",
    "            threshold = successive_threshold(labels_i, activations_i)\n",
    "            thresholds.append(threshold)\n",
    "    np.array(thresholds)\n",
    "    return(thresholds)\n",
    "\n",
    "# Input function for individual thresholds\n",
    "def equidistant_threshold(labels_i,activations_i, distance=0.1):\n",
    "    points = int(round(1/distance))+1\n",
    "    best_threshold = 0.5\n",
    "    best_f1 = 0.0\n",
    "    for i in range(points): \n",
    "        threshold = i*distance\n",
    "        #print('threshold: {}'.format(threshold))\n",
    "        pred_i = (activations_i > threshold).astype(int)\n",
    "        f1 = f1_score(labels_i, pred_i)\n",
    "        #print('f1: {}'.format(f1))\n",
    "        if(f1>best_f1):\n",
    "            #print('!!newbest!!')\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "    return(best_threshold)\n",
    "\n",
    "# Input function for successive splitting\n",
    "def successive_threshold(labels_i, activations_i, depth=10):\n",
    "    best_threshold = 0.5\n",
    "    best_f1 = 0.0\n",
    "    min_threshold = 0.1\n",
    "    max_threshold = 0.9\n",
    "    min_pred = (activations_i > min_threshold).astype(int)\n",
    "    max_pred = (activations_i > max_threshold).astype(int)\n",
    "    min_f1 = f1_score(labels_i, min_pred)\n",
    "    max_f1 = f1_score(labels_i, max_pred)\n",
    "    if (max_f1>best_f1):\n",
    "        best_f1 = max_f1\n",
    "        best_threshold = max_threshold\n",
    "    if (min_f1>best_f1):\n",
    "        best_f1 = min_f1\n",
    "        best_threshold = min_threshold    \n",
    "    for i in range(depth):\n",
    "        center = (max_threshold+min_threshold)/2\n",
    "        if(min_f1>max_f1):\n",
    "            max_threshold = center\n",
    "            max_pred = (activations_i > max_threshold).astype(int)\n",
    "            max_f1 = f1_score(labels_i, max_pred)\n",
    "            if (max_f1>best_f1):\n",
    "                best_f1 = max_f1\n",
    "                best_threshold = max_threshold\n",
    "        else:\n",
    "            min_threshold = center\n",
    "            min_pred = (activations_i > min_threshold).astype(int)\n",
    "            min_f1 = f1_score(labels_i, min_pred)\n",
    "            if (min_f1>best_f1):\n",
    "                best_f1 = min_f1\n",
    "                best_threshold = min_threshold\n",
    "    return(best_threshold)\n",
    "\n",
    "# Lazy function to find one global threshold better than 0.5 using equidistance    \n",
    "def global_eq_threshold(y_true, predictions, distance):\n",
    "    points = int(round(1/distance+1))\n",
    "    best_f1 = 0.0\n",
    "    best_threshold = 0.5\n",
    "    for i in range(points): \n",
    "        threshold = i*distance\n",
    "        y_pred = (predictions > threshold).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred, average='micro')\n",
    "        \n",
    "        if(f1>best_f1):\n",
    "            best_f1=f1\n",
    "            best_threshold = threshold\n",
    "    return(best_threshold)\n",
    "\n",
    "# Function to find global threshold better than 0.5 using successive splitting\n",
    "def global_succ_threshold(y_true, predictions, depth):\n",
    "    best_threshold = 0.5\n",
    "    best_f1 = 0.0\n",
    "    min_threshold = 0.1\n",
    "    max_threshold = 0.9\n",
    "    min_pred = (predictions > min_threshold).astype(int)\n",
    "    max_pred = (predictions > max_threshold).astype(int)\n",
    "    min_f1 = f1_score(y_true, min_pred, average='micro')\n",
    "    max_f1 = f1_score(y_true, max_pred, average='micro')\n",
    "    if (max_f1>best_f1):\n",
    "        best_f1 = max_f1\n",
    "        best_threshold = max_threshold\n",
    "    if (min_f1>best_f1):\n",
    "        best_f1 = min_f1\n",
    "        best_threshold = min_threshold\n",
    "    for i in range(depth):\n",
    "        center = (max_threshold+min_threshold)/2\n",
    "        if(min_f1>max_f1):\n",
    "            max_threshold = center\n",
    "            max_pred = (predictions > max_threshold).astype(int)\n",
    "            max_f1 = f1_score(y_true, max_pred,average='micro')\n",
    "            if (max_f1>best_f1):\n",
    "                best_f1 = max_f1\n",
    "                best_threshold = max_threshold\n",
    "        else:\n",
    "            min_threshold = center\n",
    "            min_pred = (predictions > min_threshold).astype(int)\n",
    "            min_f1 = f1_score(y_true, min_pred,average='micro')\n",
    "            if (min_f1>best_f1):\n",
    "                best_f1 = min_f1\n",
    "                best_threshold = min_threshold\n",
    "    return(best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09568756326617724\n"
     ]
    }
   ],
   "source": [
    "#Equidistant threshold finding and f1\n",
    "\n",
    "eq = np.array(thresholds(y_true,y_pred))\n",
    "\n",
    "y_pred = np.empty((predictions.shape))\n",
    "for i, threshold in enumerate(eq):\n",
    "    y_pred[i] = (predictions[i,:] > threshold).astype(int)\n",
    "\n",
    "f1 = f1_score(y_true, y_pred, average='micro')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21779322833413445\n"
     ]
    }
   ],
   "source": [
    "# Successive splitting thresholds and f1\n",
    "\n",
    "sc = np.array(thresholds(y_true, y_pred,method='successive'))\n",
    "y_pred = np.empty((predictions.shape))\n",
    "for i, threshold in enumerate(sc):\n",
    "    y_pred[i] = (predictions[i,:] > threshold).astype(int)\n",
    "\n",
    "f1 = f1_score(y_true, y_pred, average='micro')\n",
    "print (f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06798355079245075\n"
     ]
    }
   ],
   "source": [
    "# Global equidistant search thresholds and f1\n",
    "\n",
    "geq = np.array(global_eq_threshold(y_true, y_pred,0.01))\n",
    "y_pred = (predictions > geq).astype(int)\n",
    "\n",
    "f1 = f1_score(y_true, y_pred, average='micro')\n",
    "print (f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2178029667885129\n"
     ]
    }
   ],
   "source": [
    "#Global successive splitting thresholds and f1\n",
    "\n",
    "gsc = np.array(global_succ_threshold(y_true, y_pred,100))\n",
    "y_pred = (predictions > gsc).astype(int)\n",
    "\n",
    "f1 = f1_score(y_true, y_pred, average='micro')\n",
    "print (f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
