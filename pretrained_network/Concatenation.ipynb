{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import sys\n",
    "sys.path.append(\"../data_preparation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "import json\n",
    "import pickle\n",
    "# from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sekiz/FashionChallenge/.env/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import cPickle\n",
    "import gzip\n",
    "from tensorflow.python.lib.io import file_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import keras\n",
    "# from keras.applications import Xception, VGG16, VGG19, ResNet50, InceptionV3\n",
    "from keras.layers import Dense, concatenate#,GlobalAveragePooling2D, Dropout, Input\n",
    "from keras.models import Model, load_model\n",
    "# from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batch_generator import BatchGenerator, BatchSequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_batch_generator(generator_num, **kwargs):\n",
    "    \"\"\"A generator to work with multiple inputs models\n",
    "    \n",
    "    We create a model with a list of multiple input layers when \n",
    "    we use :func:`keras.layers.concatenate`. However,\n",
    "    :class:`batch_generator.BatchGenerator` returns a single tuple \n",
    "    with two arrays, which does not fit to a model with a multiple \n",
    "    input layers. Thus, with this generator, we create the necessary \n",
    "    input for such models.\n",
    "    \n",
    "    Arguments:\n",
    "        generator_num {int} -- number of generators should be created\n",
    "        \\**kwargs -- See :class:`batch_generator.BatchGenerator`\n",
    "        \n",
    "    Yields:\n",
    "        ([ndarray,...,ndarray], ndarray) -- in the tuple; list contains feature arrays from each generator, array out of the list contains the label set\n",
    "    \"\"\"\n",
    "    generators_list = [BatchGenerator(**kwargs) for i in range(generator_num)]\n",
    "    \n",
    "    while True:\n",
    "        Xy_list = [gen.next() for gen in generators_list]\n",
    "        yield [Xy[0] for Xy in Xy_list], Xy_list[0][1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Hardcoded version of the above function, \n",
    "# DOWNSIDE: You need to modify the function if the number of inputs changed\n",
    "\n",
    "def multiple_batch_generator(**kwargs):\n",
    "    \"\"\"A generator to work with multiple inputs models\n",
    "    \n",
    "    We create a model with a list of multiple input layers when \n",
    "    we use :func:`keras.layers.concatenate`. However,\n",
    "    :class:`batch_generator.BatchGenerator` returns a single tuple \n",
    "    with two arrays, which does not fit to a model with a multiple \n",
    "    input layers. Thus, with this generator, we create the necessary \n",
    "    input for such models.\n",
    "    \n",
    "    Arguments:\n",
    "        \\**kwargs -- See :class:`batch_generator.BatchGenerator`\n",
    "        \n",
    "    Yields:\n",
    "        ([ndarray,...,ndarray], ndarray) -- in the tuple; list contains feature arrays from each generator, array out of the list contains the label set\n",
    "    \"\"\"\n",
    "    \n",
    "    gen1 = BatchGenerator(**kwargs)\n",
    "    gen2 = BatchGenerator(**kwargs)\n",
    "    gen3 = BatchGenerator(**kwargs)\n",
    "#     gen4 = BatchGenerator(**kwargs)\n",
    "#     gen5 = BatchGenerator(**kwargs)\n",
    "    \n",
    "    while True:\n",
    "        Xy1 = gen1.next()\n",
    "        X1 = np.array(Xy1[0])\n",
    "        Y1 = np.array(Xy1[1])\n",
    "        X2 = np.array(gen2.next()[0])\n",
    "        X3 = np.array(gen3.next()[0])\n",
    "#         X4 = np.array(gen4.next()[0])\n",
    "#         X5 = np.array(gen5.next()[0])\n",
    "        \n",
    "        yield [X1, X2, X3], Y1\n",
    "#         yield [X1, X2, X3, X4, X5], Y1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16 = load_model('Pretrained-networks/vgg16/vgg16_3000.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_vgg16 = VGG16(weights='imagenet', include_top=False)#, input_shape=(290,290,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model_vgg16.layers):\n",
    "    model_vgg16.layers[i].trainable = False\n",
    "    model_vgg16.layers[i].name = '{}_{}'.format(layer.name, 'vgg16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_out = model_vgg16.output"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vgg16_out = GlobalAveragePooling2D()(vgg16_out)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vgg16_out = Dense(1024, activation='relu')(vgg16_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg19 = load_model('Pretrained-networks/vgg19/VGG19.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_vgg19 = VGG19(weights='imagenet', include_top=False)#, input_shape=(290,290,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model_vgg19.layers):\n",
    "    model_vgg19.layers[i].trainable = False\n",
    "    model_vgg19.layers[i].name = '{}_{}'.format(layer.name, 'vgg19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_out = model_vgg19.output"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vgg19_out = GlobalAveragePooling2D()(vgg19_out)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vgg19_out = Dense(1024, activation='relu')(vgg19_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xception = load_model('Pretrained-networks/Xception/xception.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_xception = Xception(weights='imagenet', include_top=False)#, input_shape=(290,290,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model_xception.layers):\n",
    "    model_xception.layers[i].trainable = False\n",
    "    model_xception.layers[i].name = '{}_{}'.format(layer.name, 'xception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception_out = model_xception.output"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "xception_out = GlobalAveragePooling2D()(xception_out)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "xception_out = Dense(1024, activation='relu')(xception_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inception = load_model('Pretrained-networks/inception/inceptionV3.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_inception = Inception(weights='imagenet', include_top=False)#, input_shape=(290,290,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model_inception.layers):\n",
    "    model_inception.layers[i].trainable = False\n",
    "    model_inception.layers[i].name = '{}_{}'.format(layer.name, 'inception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_out = model_inception.output"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inception_out = GlobalAveragePooling2D()(inception_out)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inception_out = Dense(1024, activation='relu')(inception_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet50 = load_model('Pretrained-networks/ResNet50/ResNet50.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_resnet50 = ResNet50(weights='imagenet', include_top=False)#, input_shape=(290,290,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model_resnet50.layers):\n",
    "    model_resnet50.layers[i].trainable = False\n",
    "    model_resnet50.layers[i].name = '{}_{}'.format(layer.name, 'resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_out = model_resnet50.output"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "resnet50_out = GlobalAveragePooling2D()(resnet50_out)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "resnet50_out = Dense(1024, activation='relu')(resnet50_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_0 = concatenate([vgg16_out, vgg19_out, resnet50_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Dense(228, activation='sigmoid', name='main_output')(merge_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[model_vgg16.input, model_vgg19.input, model_resnet50.input], outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths\n",
    "input_path = os.path.abspath('../../mlipdata/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path_train = os.path.join(input_path, 'files/train/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('pickles/binarizer.pickle', 'rb') as pickle_file:\n",
    "    binarizer = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with file_io.FileIO('../../mlipdata/server_train.pickle', mode='rb') as fp:\n",
    "        data = gzip.GzipFile(fileobj=fp)\n",
    "        y_train = cPickle.load(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([j[1:] for j in y_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data from file\n",
    "train={}\n",
    "with open(os.path.join(input_path, 'train.json')) as json_data:\n",
    "    train= json.load(json_data)\n",
    "\n",
    "train_img_url = train['images']\n",
    "train_img_url = pd.DataFrame(train_img_url)\n",
    "train_ann = train['annotations']\n",
    "train_ann = pd.DataFrame(train_ann)\n",
    "train = pd.merge(train_img_url, train_ann, on='imageId', how='inner')\n",
    "train['imageId'] = train['imageId'].astype(np.uint32)\n",
    "\n",
    "#y_train = np.array(train.labelId)\n",
    "#y_train_bin = binarizer.transform(y_train)\n",
    "\n",
    "del train_img_url\n",
    "del train_ann\n",
    "del train\n",
    "#del y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit_generator with multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "steps = int(len(y_train[:1000])/batch_size)\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use binary loss instead of categorical loss to penalize each output independently\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_num = len(model.input_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_multi = multiple_batch_generator(generator_num=input_num,\n",
    "                                           input_dir=images_path_train,\n",
    "                                           y=y_train[:1000],\n",
    "                                           batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "13/15 [=========================>....] - ETA: 1:00 - loss: 0.6833"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_gen_multi, steps_per_epoch=steps, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./ensemble_model_1000.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./ensemble_model_1000.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths\n",
    "input_path = os.path.abspath('../../mlipdata/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('pickles/binarizer.pickle', 'rb') as pickle_file:\n",
    "    binarizer = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path_validation = os.path.join(input_path, 'files/validation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with file_io.FileIO('../../mlipdata/server_validation.pickle', mode='rb') as fp:\n",
    "        data = gzip.GzipFile(fileobj=fp)\n",
    "        y_validation = cPickle.load(data)\n",
    "y_validation = np.array([j[1:] for j in y_validation])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation={}\n",
    "with open(os.path.join(input_path, 'validation.json')) as json_data:\n",
    "    validation = json.load(json_data)\n",
    "\n",
    "validation_img_url = validation['images']\n",
    "validation_img_url = pd.DataFrame(validation_img_url)\n",
    "validation_ann = validation['annotations']\n",
    "validation_ann = pd.DataFrame(validation_ann)\n",
    "validation = pd.merge(validation_img_url, validation_ann, on='imageId', how='inner')\n",
    "validation['imageId'] = validation['imageId'].astype(np.uint32)\n",
    "\n",
    "#y_validation = np.array(validation.labelId)\n",
    "#y_validation_bin = binarizer.transform(y_validation)\n",
    "\n",
    "del validation_img_url\n",
    "del validation_ann\n",
    "del validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict_generator with multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "val_steps = int(len(y_validation[:500])/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_num = len(model.input_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator_multi = multiple_batch_generator(generator_num=input_num,\n",
    "                                               input_dir=images_path_validation,\n",
    "                                               y=y_validation\n",
    "                                               [:500],\n",
    "                                               batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(val_generator_multi, steps=val_steps, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_validation[:500]\n",
    "y_pred = (predictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = precision_score(y_true, y_pred, average='micro')\n",
    "rc = recall_score(y_true, y_pred, average='micro')\n",
    "f1 = f1_score(y_true, y_pred, average='micro')\n",
    "\n",
    "print(\"Precision: {} Recall: {} F1: {}\".format(pr, rc, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
